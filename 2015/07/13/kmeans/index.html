<!DOCTYPE html>
<html>
<head><meta name="generator" content="Hexo 3.8.0">
  <meta charset="utf-8">
  
  <title>K-均值聚类算法 | simyy</title>
  <meta name="viewport" content="width=device-width">
  <meta name="description" content="聚类是一种无监督的学习算法，它将相似的数据归纳到同一簇中。K-均值是因为它可以按照k个不同的簇来分类，并且不同的簇中心采用簇中所含的均值计算而成。">
<meta name="keywords" content="算法,机器学习">
<meta property="og:type" content="article">
<meta property="og:title" content="K-均值聚类算法">
<meta property="og:url" content="http://simyy.cn/2015/07/13/kmeans/index.html">
<meta property="og:site_name" content="simyy">
<meta property="og:description" content="聚类是一种无监督的学习算法，它将相似的数据归纳到同一簇中。K-均值是因为它可以按照k个不同的簇来分类，并且不同的簇中心采用簇中所含的均值计算而成。">
<meta property="og:locale" content="zh-CN">
<meta property="og:image" content="http://simyy.cn/images/kmeans-1.jpg">
<meta property="og:image" content="http://simyy.cn/images/kmeans-2.jpg">
<meta property="og:updated_time" content="2019-12-17T02:30:47.537Z">
<meta name="twitter:card" content="summary">
<meta name="twitter:title" content="K-均值聚类算法">
<meta name="twitter:description" content="聚类是一种无监督的学习算法，它将相似的数据归纳到同一簇中。K-均值是因为它可以按照k个不同的簇来分类，并且不同的簇中心采用簇中所含的均值计算而成。">
<meta name="twitter:image" content="http://simyy.cn/images/kmeans-1.jpg">
  
    <link rel="alternative" href="/atom.xml" title="simyy" type="application/atom+xml">
  
  
    <link rel="icon" href="/favicon.ico">
  
  <link rel="stylesheet" href="/css/style.css">
  <!--[if lt IE 9]><script src="//html5shiv.googlecode.com/svn/trunk/html5.js"></script><![endif]-->
  
</head></html>
<script src="/js/hexo_resize_image.js"></script>
<body>
  <div id="container">
    <div class="mobile-nav-panel">
	<i class="icon-reorder icon-large"></i>
</div>
<header id="header">
	<h1 class="blog-title">
		<a href="/">simyy</a>
	</h1>
	<nav class="nav">
		<ul>
			<li><a href="/">主页</a></li><li><a href="/2014/07/07/book-list">书单</a></li><li><a href="/archives">归档</a></li><li><a href="/tags">标签</a></li>
			<li><a id="nav-search-btn" class="nav-icon" title="Search"></a></li>
			<li><a href="/atom.xml" id="nav-rss-link" class="nav-icon" title="RSS Feed"></a></li>
		</ul>
	</nav>
	<div id="search-form-wrap">
		<form action="//google.com/search" method="get" accept-charset="UTF-8" class="search-form"><input type="search" name="q" class="search-form-input" placeholder="Search"><button type="submit" class="search-form-submit">&#xF002;</button><input type="hidden" name="sitesearch" value="http://simyy.cn"></form>
	</div>
</header>
    <div id="main">
      


<article id="post-kmeans" class="post">
	<footer class="entry-meta-header">
		<span class="meta-elements date">
			<a href="/2015/07/13/kmeans/" class="article-date">
  <time datetime="2015-07-13T14:08:11.000Z" itemprop="datePublished">2015-07-13</time>
</a>

		</span>
        <span class="tags">
	       	
  <ul class="article-tag-list"><li class="article-tag-list-item"><a class="article-tag-list-link" href="/tags/机器学习/">机器学习</a></li><li class="article-tag-list-item"><a class="article-tag-list-link" href="/tags/算法/">算法</a></li></ul>

		</span>
		<!--span class="meta-elements author">simyy</span-->
		<div class="commentscount">
			
		</div>
	</footer>
	
	<header class="entry-header">
		
  
    <h1 class="article-title entry-title" itemprop="name">
      K-均值聚类算法
    </h1>
  

	</header>
	<div class="entry-content">
		
    	<p>聚类是一种无监督的学习算法，它将相似的数据归纳到同一簇中。K-均值是因为它可以按照k个不同的簇来分类，并且不同的簇中心采用簇中所含的均值计算而成。<br><a id="more"></a></p>
<h2 id="K-均值算法"><a href="#K-均值算法" class="headerlink" title="K-均值算法"></a>K-均值算法</h2><h3 id="算法思想"><a href="#算法思想" class="headerlink" title="算法思想"></a>算法思想</h3><p>K-均值是把数据集按照k个簇分类，其中k是用户给定的，其中每个簇是通过质心来计算簇的中心点。</p>
<p>主要步骤：</p>
<ul>
<li>随机确定k个初始点作为质心</li>
<li>对数据集中的每个数据点找到距离最近的簇</li>
<li>对于每一个簇，计算簇中所有点的均值并将均值作为质心</li>
<li>重复步骤2，直到任意一个点的簇分配结果不变<h3 id="具体实现"><a href="#具体实现" class="headerlink" title="具体实现"></a>具体实现</h3></li>
</ul>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">from</span> numpy <span class="keyword">import</span> *</span><br><span class="line"><span class="keyword">import</span> matplotlib</span><br><span class="line"><span class="keyword">import</span> matplotlib.pyplot <span class="keyword">as</span> plt</span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">loadDataSet</span><span class="params">(fileName)</span>:</span>      <span class="comment">#general function to parse tab -delimited floats</span></span><br><span class="line">    dataMat = []                <span class="comment">#assume last column is target value</span></span><br><span class="line">    fr = open(fileName)</span><br><span class="line">    <span class="keyword">for</span> line <span class="keyword">in</span> fr.readlines():</span><br><span class="line">        curLine = line.strip().split(<span class="string">'\t'</span>)</span><br><span class="line">        fltLine = map(float,curLine) <span class="comment">#map all elements to float()</span></span><br><span class="line">        dataMat.append(fltLine)</span><br><span class="line">    <span class="keyword">return</span> dataMat</span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">distEclud</span><span class="params">(vecA, vecB)</span>:</span></span><br><span class="line">    <span class="keyword">return</span> sqrt(sum(power(vecA - vecB, <span class="number">2</span>))) <span class="comment">#la.norm(vecA-vecB)</span></span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">randCent</span><span class="params">(dataSet, k)</span>:</span></span><br><span class="line">    n = shape(dataSet)[<span class="number">1</span>]</span><br><span class="line">    centroids = mat(zeros((k,n)))<span class="comment">#create centroid mat</span></span><br><span class="line">    <span class="keyword">for</span> j <span class="keyword">in</span> range(n):<span class="comment">#create random cluster centers, within bounds of each dimension</span></span><br><span class="line">        minJ = min(dataSet[:,j]) </span><br><span class="line">        rangeJ = float(max(dataSet[:,j]) - minJ)</span><br><span class="line">        centroids[:,j] = mat(minJ + rangeJ * random.rand(k,<span class="number">1</span>))</span><br><span class="line">    <span class="keyword">return</span> centroids</span><br><span class="line">    </span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">kMeans</span><span class="params">(dataSet, k, distMeas=distEclud, createCent=randCent)</span>:</span></span><br><span class="line">    m = shape(dataSet)[<span class="number">0</span>]</span><br><span class="line">    clusterAssment = mat(zeros((m,<span class="number">2</span>)))<span class="comment">#create mat to assign data points </span></span><br><span class="line">                                      <span class="comment">#to a centroid, also holds SE of each point</span></span><br><span class="line">    centroids = createCent(dataSet, k)</span><br><span class="line">    clusterChanged = <span class="keyword">True</span></span><br><span class="line">    <span class="keyword">while</span> clusterChanged:</span><br><span class="line">        clusterChanged = <span class="keyword">False</span></span><br><span class="line">        <span class="keyword">for</span> i <span class="keyword">in</span> range(m):<span class="comment">#for each data point assign it to the closest centroid</span></span><br><span class="line">            minDist = inf; minIndex = <span class="number">-1</span></span><br><span class="line">            <span class="keyword">for</span> j <span class="keyword">in</span> range(k):</span><br><span class="line">                distJI = distMeas(centroids[j,:],dataSet[i,:])</span><br><span class="line">                <span class="keyword">if</span> distJI &lt; minDist:</span><br><span class="line">                    minDist = distJI; minIndex = j</span><br><span class="line">            <span class="keyword">if</span> clusterAssment[i,<span class="number">0</span>] != minIndex: clusterChanged = <span class="keyword">True</span></span><br><span class="line">            clusterAssment[i,:] = minIndex,minDist**<span class="number">2</span></span><br><span class="line">        <span class="keyword">for</span> cent <span class="keyword">in</span> range(k):<span class="comment">#recalculate centroids</span></span><br><span class="line">            ptsInClust = dataSet[nonzero(clusterAssment[:,<span class="number">0</span>].A==cent)[<span class="number">0</span>]]<span class="comment">#get all the point in this cluster</span></span><br><span class="line">            centroids[cent,:] = mean(ptsInClust, axis=<span class="number">0</span>) <span class="comment">#assign centroid to mean </span></span><br><span class="line">            <span class="keyword">print</span> ptsInClust</span><br><span class="line">            <span class="keyword">print</span> mean(ptsInClust, axis=<span class="number">0</span>) </span><br><span class="line">            <span class="keyword">return</span></span><br><span class="line">    <span class="keyword">return</span> centroids, clusterAssment</span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">clusterClubs</span><span class="params">(numClust=<span class="number">5</span>)</span>:</span></span><br><span class="line">    datList = []</span><br><span class="line">    <span class="keyword">for</span> line <span class="keyword">in</span> open(<span class="string">'places.txt'</span>).readlines():</span><br><span class="line">        lineArr = line.split(<span class="string">'\t'</span>)</span><br><span class="line">        datList.append([float(lineArr[<span class="number">4</span>]), float(lineArr[<span class="number">3</span>])])</span><br><span class="line">    datMat = mat(datList)</span><br><span class="line">    myCentroids, clustAssing = biKmeans(datMat, numClust, distMeas=distSLC)</span><br><span class="line">    fig = plt.figure()</span><br><span class="line">    rect=[<span class="number">0.1</span>,<span class="number">0.1</span>,<span class="number">0.8</span>,<span class="number">0.8</span>]</span><br><span class="line">    scatterMarkers=[<span class="string">'s'</span>, <span class="string">'o'</span>, <span class="string">'^'</span>, <span class="string">'8'</span>, <span class="string">'p'</span>, \</span><br><span class="line">                    <span class="string">'d'</span>, <span class="string">'v'</span>, <span class="string">'h'</span>, <span class="string">'&gt;'</span>, <span class="string">'&lt;'</span>]</span><br><span class="line">    axprops = dict(xticks=[], yticks=[])</span><br><span class="line">    ax0=fig.add_axes(rect, label=<span class="string">'ax0'</span>, **axprops)</span><br><span class="line">    imgP = plt.imread(<span class="string">'Portland.png'</span>)</span><br><span class="line">    ax0.imshow(imgP)</span><br><span class="line">    ax1=fig.add_axes(rect, label=<span class="string">'ax1'</span>, frameon=<span class="keyword">False</span>)</span><br><span class="line">    <span class="keyword">for</span> i <span class="keyword">in</span> range(numClust):</span><br><span class="line">        ptsInCurrCluster = datMat[nonzero(clustAssing[:,<span class="number">0</span>].A==i)[<span class="number">0</span>],:]</span><br><span class="line">        markerStyle = scatterMarkers[i % len(scatterMarkers)]</span><br><span class="line">        ax1.scatter(ptsInCurrCluster[:,<span class="number">0</span>].flatten().A[<span class="number">0</span>], ptsInCurrCluster[:,<span class="number">1</span>].flatten().A[<span class="number">0</span>], marker=markerStyle, s=<span class="number">90</span>)</span><br><span class="line">    ax1.scatter(myCentroids[:,<span class="number">0</span>].flatten().A[<span class="number">0</span>], myCentroids[:,<span class="number">1</span>].flatten().A[<span class="number">0</span>], marker=<span class="string">'+'</span>, s=<span class="number">300</span>)</span><br><span class="line">    plt.show()</span><br></pre></td></tr></table></figure>
<h3 id="结果"><a href="#结果" class="headerlink" title="结果"></a>结果</h3><p><img src="/images/kmeans-1.jpg" alt="K均值"></p>
<h3 id="算法收敛"><a href="#算法收敛" class="headerlink" title="算法收敛"></a>算法收敛</h3><p>设目标函数为</p>
<p>$$J(c, \mu) = \sum _{i=1}^m (x_i - \mu_{c_{(i)}})^2$$</p>
<p>Kmeans算法是将J调整到最小，每次调整质心，J值也会减小，同时c和$\mu$也会收敛。由于该函数是一个非凸函数，所以不能保证得到全局最优，智能确保局部最优解。</p>
<h2 id="二分K均值算法"><a href="#二分K均值算法" class="headerlink" title="二分K均值算法"></a>二分K均值算法</h2><p>为了克服K均值算法收敛于局部最小值的问题，提出了二分K均值算法。</p>
<h3 id="算法思想-1"><a href="#算法思想-1" class="headerlink" title="算法思想"></a>算法思想</h3><p>该算法首先将所有点作为一个簇，然后将该簇一分为2，之后选择其中一个簇继续进行划分，划分规则是按照最大化SSE（目标函数）的值。</p>
<p>主要步骤：</p>
<ul>
<li>将所有点看成一个簇</li>
<li>计算每一个簇的总误差</li>
<li>在给定的簇上进行K均值聚类，计算将簇一分为二的总误差</li>
<li>选择使得误差最小的那个簇进行再次划分</li>
<li>重复步骤2，直到簇的个数满足要求</li>
</ul>
<h3 id="具体实现-1"><a href="#具体实现-1" class="headerlink" title="具体实现"></a>具体实现</h3><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">biKMeans</span><span class="params">(dataSet, k, distMeans=distEclud)</span>:</span></span><br><span class="line">    m, n = shape(dataSet)</span><br><span class="line">    clusterAssment = mat(zeros((m, <span class="number">2</span>))) <span class="comment"># init all data for index 0</span></span><br><span class="line">    centroid = mean(dataSet, axis=<span class="number">0</span>).tolist()</span><br><span class="line">    centList = [centroid]</span><br><span class="line">    <span class="keyword">for</span> i <span class="keyword">in</span> range(m):</span><br><span class="line">        clusterAssment[i, <span class="number">1</span>] = distMeans(mat(centroid), dataSet[i, :]) ** <span class="number">2</span></span><br><span class="line">    <span class="keyword">while</span> len(centList) &lt; k:</span><br><span class="line">        lowestSSE = inf</span><br><span class="line">        <span class="keyword">for</span> i <span class="keyword">in</span> range(len(centList)):</span><br><span class="line">            cluster = dataSet[nonzero(clusterAssment[:, <span class="number">0</span>].A == i)[<span class="number">0</span>], :] <span class="comment"># get the clust data of i</span></span><br><span class="line">            centroidMat, splitCluster = kMeans(cluster, <span class="number">2</span>, distMeans)</span><br><span class="line">            sseSplit = sum(splitCluster[:, <span class="number">1</span>]) <span class="comment">#all sse</span></span><br><span class="line">            sseNotSplit = sum(clusterAssment[nonzero(clusterAssment[:, <span class="number">0</span>].A != i)[<span class="number">0</span>], <span class="number">1</span>]) <span class="comment"># error sse</span></span><br><span class="line">            <span class="comment">#print sseSplit, sseNotSplit</span></span><br><span class="line">            <span class="keyword">if</span> sseSplit + sseNotSplit &lt; lowestSSE:</span><br><span class="line">                bestCentToSplit = i</span><br><span class="line">                bestNewCent = centroidMat</span><br><span class="line">                bestClust = splitCluster.copy()</span><br><span class="line">                lowerSEE = sseSplit + sseNotSplit</span><br><span class="line">        <span class="keyword">print</span> bestClust</span><br><span class="line">        bestClust[nonzero(bestClust[:, <span class="number">0</span>].A == <span class="number">1</span>)[<span class="number">0</span>], <span class="number">0</span>] = len(centList)</span><br><span class="line">        bestClust[nonzero(bestClust[:, <span class="number">0</span>].A == <span class="number">0</span>)[<span class="number">0</span>], <span class="number">0</span>] = bestCentToSplit</span><br><span class="line">        <span class="keyword">print</span> bestClust</span><br><span class="line">        <span class="keyword">print</span> <span class="string">'the bestCentToSplit is: '</span>,bestCentToSplit</span><br><span class="line">        <span class="keyword">print</span> <span class="string">'the len of bestClustAss is: '</span>, len(bestClust)</span><br><span class="line">        centList[bestCentToSplit] = bestNewCent[<span class="number">0</span>, :].tolist()[<span class="number">0</span>]</span><br><span class="line">        centList.append(bestNewCent[<span class="number">1</span>, :].tolist()[<span class="number">0</span>])</span><br><span class="line">        <span class="keyword">print</span> clusterAssment</span><br><span class="line">        clusterAssment[nonzero(clusterAssment[:, <span class="number">0</span>].A == bestCentToSplit)[<span class="number">0</span>], :] = bestClust</span><br><span class="line">        <span class="keyword">print</span> clusterAssment</span><br><span class="line">    <span class="keyword">return</span> mat(centList), clusterAssment</span><br></pre></td></tr></table></figure>
<h3 id="结果-1"><a href="#结果-1" class="headerlink" title="结果"></a>结果</h3><p><img src="/images/kmeans-2.jpg" alt="二分K均值"></p>

    
	</div>
	
    
<nav id="article-nav">
  
    <a href="/2015/08/18/sqlalchemy/" id="article-nav-newer" class="article-nav-link-wrap">
      <strong class="article-nav-caption">Newer</strong>
      <div class="article-nav-title">
        
          sqlalchemy(一) 基本操作
        
      </div>
    </a>
  
  
    <a href="/2015/06/25/regression/" id="article-nav-older" class="article-nav-link-wrap">
      <strong class="article-nav-caption">Older</strong>
      <div class="article-nav-title">
        
          回归算法
        
      </div>
    </a>
  
</nav>

  
</article>







    </div>
    <div class="mb-search">
  <form action="//google.com/search" method="get" accept-charset="utf-8">
    <input type="search" name="q" results="0" placeholder="Search">
    <input type="hidden" name="q" value="site:simyy.cn">
  </form>
</div>
<footer id="footer">
	<h1 class="footer-blog-title">
		<a href="/">simyy</a>
	</h1>
    &nbsp;&nbsp;
	<span class="copyright">
		&copy; 2020 simyy  Powered by <a href="http://hexo.io/" target="_blank">Hexo</a>
	</span>
</footer>

    

<script src="https://cdn.bootcss.com/jquery/2.1.3/jquery.min.js"></script>


<link rel="stylesheet" href="/fancybox/jquery.fancybox.css" media="screen" type="text/css">
<script src="/fancybox/jquery.fancybox.pack.js"></script>


<script src="/js/script.js"></script>

  </div>
</body>
</html>