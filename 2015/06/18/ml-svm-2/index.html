<!DOCTYPE html>
<html>
<head><meta name="generator" content="Hexo 3.8.0">
  <meta charset="utf-8">
  
  <title>SVM-非线性支持向量机及SMO算法 | simyy</title>
  <meta name="viewport" content="width=device-width">
  <meta name="description" content="学习支持向量机。">
<meta name="keywords" content="机器学习">
<meta property="og:type" content="article">
<meta property="og:title" content="SVM-非线性支持向量机及SMO算法">
<meta property="og:url" content="http://simyy.cn/2015/06/18/ml-svm-2/index.html">
<meta property="og:site_name" content="simyy">
<meta property="og:description" content="学习支持向量机。">
<meta property="og:locale" content="zh-CN">
<meta property="og:image" content="http://simyy.cn/images/ml-svm-2-1.jpg">
<meta property="og:image" content="http://simyy.cn/images/ml-svm-2-2.jpg">
<meta property="og:updated_time" content="2017-04-08T09:34:31.000Z">
<meta name="twitter:card" content="summary">
<meta name="twitter:title" content="SVM-非线性支持向量机及SMO算法">
<meta name="twitter:description" content="学习支持向量机。">
<meta name="twitter:image" content="http://simyy.cn/images/ml-svm-2-1.jpg">
  
    <link rel="alternative" href="/atom.xml" title="simyy" type="application/atom+xml">
  
  
    <link rel="icon" href="/favicon.ico">
  
  <link rel="stylesheet" href="/css/style.css">
  <!--[if lt IE 9]><script src="//html5shiv.googlecode.com/svn/trunk/html5.js"></script><![endif]-->
  
</head></html>
<body>
  <div id="container">
    <div class="mobile-nav-panel">
	<i class="icon-reorder icon-large"></i>
</div>
<header id="header">
	<h1 class="blog-title">
		<a href="/">simyy</a>
	</h1>
	<nav class="nav">
		<ul>
			<li><a href="/">Home</a></li><li><a href="/archives">Archives</a></li>
			<li><a id="nav-search-btn" class="nav-icon" title="Search"></a></li>
			<li><a href="/atom.xml" id="nav-rss-link" class="nav-icon" title="RSS Feed"></a></li>
		</ul>
	</nav>
	<div id="search-form-wrap">
		<form action="//google.com/search" method="get" accept-charset="UTF-8" class="search-form"><input type="search" name="q" class="search-form-input" placeholder="Search"><button type="submit" class="search-form-submit">&#xF002;</button><input type="hidden" name="sitesearch" value="http://simyy.cn"></form>
	</div>
</header>
    <div id="main">
      <article id="post-ml-svm-2" class="post">
	<footer class="entry-meta-header">
		<span class="meta-elements date">
			<a href="/2015/06/18/ml-svm-2/" class="article-date">
  <time datetime="2015-06-18T14:44:44.000Z" itemprop="datePublished">2015-06-18</time>
</a>

		</span>
        <span class="tags">
	       	
  <ul class="article-tag-list"><li class="article-tag-list-item"><a class="article-tag-list-link" href="/tags/机器学习/">机器学习</a></li></ul>

		</span>
		<!--span class="meta-elements author">simyy</span-->
		<div class="commentscount">
			
		</div>
	</footer>
	
	<header class="entry-header">
		
  
    <h1 class="article-title entry-title" itemprop="name">
      SVM-非线性支持向量机及SMO算法
    </h1>
  

	</header>
	<div class="entry-content">
		
    	<p>学习支持向量机。<br><a id="more"></a></p>
<h2 id="线性不可分情况"><a href="#线性不可分情况" class="headerlink" title="线性不可分情况"></a>线性不可分情况</h2><p>线性可分问题的支持向量机学习方法，对线性不可分训练数据是不适用的，为了满足函数间隔大于1的约束条件，可以对每个样本$(x_i, y_i)$引进一个松弛变量$\xi_i \ge 0$，使函数间隔加上松弛变量大于等于1,，</p>
<p>$$y_i (w \cdot x_i + b) \ge 1 - \xi_i$$</p>
<p>目标函数变为</p>
<p>$$\frac 1 2 {||w||^2} +  C \sum_{j=1}^N \xi_i$$</p>
<p>其中，C&gt;0称为惩罚参数，值越大对误分类的惩罚越大，值越小对误分类的惩罚越小。</p>
<p>因此，最小化目标函数也就是使$\frac 1 2 {||w||^2}$尽量小（间隔尽量大），同时使误分类点的个数尽量小。</p>
<p>线性不可分的线性支持向量机的学习问题变成如下凸二次规划问题：</p>
<p>$$ \min_{w,b,\xi}\frac 1 2 {||w||}^2 + C \sum_{i=1}^N \xi_i \\<br>s.t. \quad y_i(w \cdot x_i + b) \ge 1 -  \xi_i, \quad i=1,2,…,N, \xi_i \ge 0, i=1,2,…,N$$</p>
<h3 id="线性支持向量学习算法"><a href="#线性支持向量学习算法" class="headerlink" title="线性支持向量学习算法"></a>线性支持向量学习算法</h3><ul>
<li>选择惩罚参数C&gt;0，构造并求解凸二次规划问题</li>
</ul>
<p>$$ \min_\alpha \frac 1 2 \sum_{i=1}^N \sum_{j=1}^N \alpha_i \alpha_j y_i y_j (x_i \cdot x_j) - \sum_{i=1}^N \alpha_i\\<br>s.t. \quad \sum_{i=1}^N \alpha_i y_i = 0 \\<br>0 \le \alpha_i \le C, i=1,2,…,N$$</p>
<p>求得最优解$\alpha^*=(\alpha_1^*, \alpha_2^*, … , \alpha_N^*)^T$</p>
<ul>
<li>计算$w^*=\sum_{i=1}^N \alpha_i^* y_i x_i$</li>
</ul>
<p>选择$\alpha^*$的一个分量$\alpha_j^*$适合条件$0&lt;\alpha_j^*&lt;C$，计算</p>
<p>$$b^*=y_i - \sum_{i=1}^N y_i \alpha_i^*(x_i \cdot x_j)$$</p>
<ul>
<li>求得分离超平面</li>
</ul>
<p>$$w^* \cdot x + b^* = 0$$</p>
<p>分类决策函数：</p>
<p>$$f(x) = sign(w^* \cdot x + b^*)$$</p>
<h2 id="核函数"><a href="#核函数" class="headerlink" title="核函数"></a>核函数</h2><p>用线性分类方法求解非线性分类问题分为两步：首先使用一个变换将原空间的数据映射到新空间；然后在新空间里用线性分类学习方法从训练数据中学习分类模型。</p>
<p><img src="/images/ml-svm-2-1.jpg" alt="核函数的空间转换"></p>
<p>核技巧应用在支持向量机的基本思想：通过一个非线性变换将输入空间（欧式空间$R^n$或离散集合）对应于一个特征空间（希尔伯特空间H），使得在输入空间$R^n$中的超曲面模型对应于特征空间H中的超平面模型（支持向量机）。</p>
<h2 id="非线性支持向量分类机"><a href="#非线性支持向量分类机" class="headerlink" title="非线性支持向量分类机"></a>非线性支持向量分类机</h2><h3 id="非线性支持向量机"><a href="#非线性支持向量机" class="headerlink" title="非线性支持向量机"></a>非线性支持向量机</h3><p>从非线性分类训练集，通过核函数与间隔最大化或凸二次规划，学习得到的分类决策函数：</p>
<p>$$f(x)=sign(\sum_{i=1}^N \alpha_i^*y_i K(x,x_i) + b^*)$$</p>
<p>称为非线性支持向量，$K(x,z)$是正定核函数。</p>
<h3 id="学习算法"><a href="#学习算法" class="headerlink" title="学习算法"></a>学习算法</h3><ul>
<li>选择适当的核函数$K(x,z)$和适当的参数C，构造并求解最优化问题</li>
</ul>
<p>$$\min_\alpha \frac 1 2 \sum_{i=1}^N \sum_{j=1}^N \alpha_i \alpha_j y_i y_j K(x_i, x_j) - \sum_{i=1}^N \alpha_i\\<br>s.t. \quad \sum_{i=1}^N \alpha_i y_i = 0, 0&lt;\alpha_i&lt;C,i=1,2,…,N$$</p>
<p>求解最优解$\alpha^*=(\alpha_1^*, \alpha_2^*,…,\alpha_N^*)$</p>
<ul>
<li>选择$\alpha^*$的第一个正分量$0&lt;\alpha_j^*&lt;C$，计算</li>
</ul>
<p>$$b^*=y_i - \sum_{i=1}^N \alpha_i^* y_i K(x_i \cdot x_j)$$</p>
<ul>
<li>构造决策函数</li>
</ul>
<p>$$f(x)=sign(\sum_{i=1}^N \alpha_i^* y_i K(x \cdot x_i) + b^*)$$</p>
<h2 id="序列最小优化算法"><a href="#序列最小优化算法" class="headerlink" title="序列最小优化算法"></a>序列最小优化算法</h2><blockquote>
<p>SMO算法是一种启发式算法。如果所有变量都满足KKT条件，那么这个最优化问题就解决了（KKT问题是该最优化问题的充要条件），否则，选择两个变量，固定其他变量，针对这两个变量构造二次规划问题。该方法会使原始二次规划问题的目标函数变小，不断分解自问题并对子问题求解进而达到求解原问题的目的。</p>
</blockquote>
<p>由于</p>
<p>$$\sum_{i=1}^N \alpha_i y_i = 0$$</p>
<p>所以</p>
<p>$$\alpha_i = - \frac 1 {y_i} \sum_{i=2}^N \alpha_i y_i$$</p>
<h3 id="两个变量的二次规划求解"><a href="#两个变量的二次规划求解" class="headerlink" title="两个变量的二次规划求解"></a>两个变量的二次规划求解</h3><p>假设选择两个变量$\alpha_1，\alpha_2$，</p>
<p>$$\min_{\alpha_1\alpha_2} \quad = \frac 1 2 K_{11} \alpha_1^2 + \frac 1 2 K_{22} \alpha_2^2  + y_1 y_2 K_{12} \alpha_1 \alpha_2 \\<br>\quad (\alpha_1 + \alpha_2) + y_1 \alpha_1 \sum_{i=3}^N y_i \alpha_i K_{i1} + y_2\alpha_2\sum_{i=3}^N y_i \alpha_i K_{12} \\<br>s.t. \quad \alpha_1 y_1 + \alpha_2 y_2 = - \sum_{i=3}^N y_i \alpha_i = \xi \\<br>0 \le \alpha_i \le C, i=1,2$$</p>
<p>由于只有两个变量$(\alpha_i,\alpha_j)$，因此根据两变量的符号情况约束条件可用二位空间中的图表示（参考$\alpha_1 y_1 + \alpha_2 y_2 = \xi(常数)$），</p>
<p><img src="/images/ml-svm-2-2.jpg" alt="二变量优化问题"></p>
<p>L和H是$\alpha$取值的最小和最大值，如果$y_i != y_j$，则</p>
<p>$$L=\max(0,\alpha_2 - \alpha_1), H=\min(C,C+\alpha_2-\alpha_1)$$</p>
<p>如果$y_i = y_j$，则</p>
<p>$$L=\max(0,\alpha_2 + \alpha_1 + C), H=\min(C,\alpha_2+\alpha_1)$$</p>
<p>令</p>
<p>$$g(x) = \sum_{i=1}^N \alpha_i y_i K(x_i, x) + b$$</p>
<p>得到误差值：</p>
<p>$$E_i = g(x_i) - y_i = ( \sum_{i=1}^N \alpha_i y_i K(x_i, x) + b) - y_i$, \quad i = 1,2$$</p>
<p>此最优问题的解是：</p>
<p>$$\alpha_2^{new} = \alpha_2^{old} + y_2 \frac {(E_1 - E_2)} \eta$$</p>
<p>其中，</p>
<p>$$\eta = K_{11} + K_{22} - 2K_{12} = {||\phi(x_1) - \phi(x_2)||}^2$$</p>
<p>$\phi(x)$为输入空间到特征空间的映射，经过剪辑后是</p>
<p>$$f(n)=\begin{cases}<br>H,\quad \alpha_2^{new} &gt; H \\<br>\alpha_2^{new}, \quad L \le \alpha_2^{new} \le H \\<br>L,\quad \alpha_2^{new} &lt; L \end{cases}$$</p>
<p>则$\alpha_1^{new}$为</p>
<p>$$\alpha_1^{new} = \alpha_1^{old} + y_1 y_2 (\alpha_2^{old} - \alpha_2^{new})$$</p>
<h3 id="变量的选择方法"><a href="#变量的选择方法" class="headerlink" title="变量的选择方法"></a>变量的选择方法</h3><p>SMO算法在每个子问题中选择两个变量优化，其中至少一个变量是违反KKT条件的。</p>
<p>1.第1个变量的选择</p>
<p>SMO算法在外层循环中选取违反KKT条件最严重的样本点，并将其对应的变量作为第1个变量，KKT条件如下</p>
<p>$$\alpha_i = 0 &lt;=&gt; y_i g(x_i) \ge 1 \\<br>0 &lt; \alpha_i &lt; C &lt;=&gt; y_i g(x_i)=1 \\<br>\alpha_i = C &lt;=&gt; y_i g(x_i) \le 1$$</p>
<p>其中，$g(x_i) = \sum_{j=1}^N \alpha_j y_j K(x_i,x_j)+b$。</p>
<p>该检验在$\epsilon$范围内进行的，在校验过程中，外层循环首先遍历所有满足条件$0&lt;\alpha_i&lt;C$的样本点，即在间隔边界上的支持向量点，检验它们是否满足KKT条件。如果这些样本点都满足KKT条件，那么遍历整个训练集，检验它们是否满足KKT条件。</p>
<p>2.第2个变量的选择</p>
<p>SMO算法在内层循环，假设在外层循环中已经找到第一个变量$\alpha_1$，现在要在内层循环中找到第2个变量$\alpha_2$，第2个变量选择的标准是希望能使$\alpha_2$有足够的变化。根据上一节可知，$\alpha_2^{new}$是依赖$|E_1 - E_2|$的，为了加快计算速度，最简单的做法是选择$|E_1 - E_2|$最大的（如果$E_1$为负值，则选择最大的$E_i$作为$E_2$，否则选择最小的$E_i$为$E_2$，需要保存所有的$E_i$）。</p>
<p>3.计算阈值b和差值$E_i$</p>
<p>在每次完成两个变量优化后，都要重新计算阈值b。</p>
<p>由KKT条件得</p>
<p>$$\sum_{i=1}^N \alpha_i y_i K_{i1} + b = y_i$$</p>
<p>从而</p>
<p>$$b_1^{new} = y_1 - \sum_{i=3}^N \alpha_i y_i K_{i1} - \alpha_1^{new} y_1 K_{11} - \alpha_2^{new} y_2 K_{21}$$</p>
<p>由于$E_i = g(x_i) - y_i = ( \sum_{i=1}^N \alpha_i y_i K(x_i, x) + b) - y_i$, \quad i = 1,2$，则</p>
<p>$$E_1 = g(x_1) - y_1 = \sum_{i=3}^N \alpha_i y_i K_{i1} + \alpha_1^{old} y_1 K_{11} + \alpha_2^{old} y_2 K_{21} + b^{old} - y_1$$</p>
<p>将上式中的$y_i -  \sum_{i=3}^N \alpha_i y_i K_{i1} $代入$b_1^{new}$的公式中，得到</p>
<p>$$b_1^{new} = -E_1 - y_1 K_{11} (\alpha_1^{new} - \alpha_1^{old} ) - y_2 K_{21} (\alpha_2^{new} - \alpha_2^{old} ) + b^old$$</p>
<p>对于b的取值：</p>
<p>$$b^{new}=\begin{cases}b_1^{new}=b_2^{new}, \quad 0 &lt; \alpha_i^{new} &lt; C, i =1,2 \\<br>\frac {b_1^{new} + b_2^{new}} 2,\quad \alpha_i^{new} == 0 or C，满足KKT条件\end{cases}$$</p>

    
	</div>
	
    
<nav id="article-nav">
  
    <a href="/2015/06/24/logistic/" id="article-nav-newer" class="article-nav-link-wrap">
      <strong class="article-nav-caption">Newer</strong>
      <div class="article-nav-title">
        
          logistic回归
        
      </div>
    </a>
  
  
    <a href="/2015/06/17/ml-svm-1/" id="article-nav-older" class="article-nav-link-wrap">
      <strong class="article-nav-caption">Older</strong>
      <div class="article-nav-title">
        
          SVM-线性可分支持向量机
        
      </div>
    </a>
  
</nav>

  
</article>





    </div>
    <div class="mb-search">
  <form action="//google.com/search" method="get" accept-charset="utf-8">
    <input type="search" name="q" results="0" placeholder="Search">
    <input type="hidden" name="q" value="site:simyy.cn">
  </form>
</div>
<footer id="footer">
	<h1 class="footer-blog-title">
		<a href="/">simyy</a>
	</h1>
    &nbsp;&nbsp;
	<span class="copyright">
		&copy; 2019 simyy  Powered by <a href="http://hexo.io/" target="_blank">Hexo</a>
	</span>
</footer>

    

<script src="https://cdn.bootcss.com/jquery/2.1.3/jquery.min.js"></script>


<link rel="stylesheet" href="/fancybox/jquery.fancybox.css" media="screen" type="text/css">
<script src="/fancybox/jquery.fancybox.pack.js"></script>


<script src="/js/script.js"></script>

  </div>
</body>
</html>